# Render

## Goals

1. Render is not required to be run separately. This is exposed as a means of allowing users a deeper entry point for install-time customization.

2. This renders all the assets necessary to bring up a cluster on to disk. This allows users to customize assets without over-parameterizing the `InstallConfig`.

3. Allow user to commit the assets that describe a cluster.

## Non-goals

1. Render is incapable of allowing users to customize cluster objects beyond those already supported by the object's operator.

## Overview

Render has 3 steps:

1. Validate `InstallConfig` object. If `install-config.yaml` file is not present fallback to init phase to generate `InstallConfig` object.

2. Generate all the required TLS assets for the cluster.

3. Use `operator render self` interface to generate the cluster objects for all the operators.

Render puts all the assets on disk for user customization or next phase of the installer.

## Detailed design

### Idempotency

Re-running the `installer render` renders the manifests to disk again, overwriting the older manifests in the directory.

### Input

Render phase accepts a valid `InstallConfig` object that exists at `install-config.yaml` in the current directory or the directory specified by `--assets-dir` flag.

### InstallConfig Validation

Render needs to perform 3 kinds of validation:

1. Validate configuration options are known. e.g. networking provider is known.

2. Platform configuration validation. This also includes validating all node pools belong to the specified platform.

3. Ensure `master` node pool exists and has valid configuration.

### TLS asset generation

Generate all the TLS assets required for the cluster and their corresponding Kubernetes secrets. All this needs to be go code rather than terraform templates.

Some of the TLS assets that need to be generated are:
1. root-ca
2. kube-ca
3. aggregator-ca
4. etcd-ca
5. apiserver
6. ingress and more

### Rendering operator manifests

1. Historically, the installer had manifests for all the cluster objects that are required to run the operator. For example, deployment manifest for the operator, service account, roles/rolebindings and operator config etc. So changes to the installer were required to test any change in the operator. This meant that the first indication if the operator had broken install was after the operator changes were merged in its repository and then operator was updated in the installer repository.

2. Also, all the cluster objects required by the operator to functions had to be managed by the installer team.

Therefore, to allow operator teams to iterate and control all aspects of an operator, the installer needs a process to delegate the `InstallConfig` object to each operator in render phase to generate iteself and all other cluster objects necessary for it to function correctly.

#### Prerequisites

1. Render cannot assume container runtime on host.
2. Render needs to be successfully on (at least) Linux and Darwin systems.

#### Solutions

1. Vendor operators

    One way to achieve rendering is to vendor operator's code into installer and hook operator defined render function in installer's Render phase.

    Pros:

    * No extra work for cross-platform compile for various operators.
    * Single simple go binary for installer.

    Cons:

    * On operator repository, CI needs to update the toml file and run re-vendor to run install test in their PR.

2. Git submodules

    Installer repo uses git submodules to import operators and then asserts **build and render interfaces** between installer and operator to hook operator into installer's Render phase.

    Installer uses a build interface to build all the operators as binaries at build time and then packages them along side the installer binary. The render step uses the shipped operator binary to render manifests using the render interface.

    Pros:

    * Installer repo is smaller.
    * CI is much easier to work as it doesn't have to deal with go vendoring and only git submodules to replace/update the operator submodules during testing.

    Cons:

    * All operator repositories must be capable of building cross-platform binaries. Previously the operators have only built Linux binaries.

**TODO** Add the preferred solution or other approaches.

### Output

The render phase renders all the assets into following directories in the current working directory or the directory specified by `--asset-dir` flag.

#### auth

This directory has assets that can be used to authenticate with the cluster for various purposes. For example, `kubeconfig` with admin privileges will exist in this directory.

#### manifests

This directory consists of all the manifests rendered by each operator and the secrets generated from TLS assets.

### tls

This directory consists of all the TLS assets generated by the installer.

**IMPORTANT:** Some TLS assets for example, the `root-ca.key` will be written to disk and should be not be stored in insecure/public repositories.

### Example render output

```
./install-config.yaml
./auth/kubeconfig-admin
./auth/kubeconfig-bootstrap
./manifests/kube-core-operator.yaml
./manifests/kube-core-config.yaml
./manifests/kube-core-operator-sa.yaml
...
./tls/root-ca.crt
./tls/root-ca.key
./tls/kube-ca.crt
./tls/kube-ca.key
```
